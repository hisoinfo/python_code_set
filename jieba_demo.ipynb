{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/fh/grdldj5d5h90wkfrhrdxpbp40000gn/T/jieba.cache\n",
      "Loading model cost 1.265 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福|是|创新办|主任|也|是|云计算|方面|的|专家\n"
     ]
    }
   ],
   "source": [
    "# 用户添加自定词库 jieba.load_userdict(file_name)\n",
    "'''\n",
    "词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：\n",
    "词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。\n",
    "file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。\n",
    "'''\n",
    "str_demo = '李小福是创新办主任也是云计算方面的专家'\n",
    "jieba.load_userdict('user_dict.txt')\n",
    "seg_user = jieba.cut(str_demo)\n",
    "print('|'.join(seg_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg1: 如果|放到|post|中|将|出错|。\n",
      "seg2: 如果|放到|post|中|将|出错|。\n",
      "seg3: 「|台中|」|正确|应该|不会|被|切开\n",
      "seg4: 「|台|中|」|正确|应该|不会|被|切开\n"
     ]
    }
   ],
   "source": [
    "# 调整词典\n",
    "'''\n",
    "使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。\n",
    "'''\n",
    "\n",
    "test_str = '如果放到post中将出错。'\n",
    "seg1 = jieba.cut(test_str, HMM=False)\n",
    "print('seg1: ' + '|'.join(seg1))\n",
    "# 改变词频\n",
    "jieba.suggest_freq(('中', '将'), True)\n",
    "seg2 = jieba.cut(test_str, HMM=False)\n",
    "print('seg2: ' + '|'.join(seg2))\n",
    "\n",
    "test_str2 = '「台中」正确应该不会被切开'\n",
    "jieba.suggest_freq('台中', True)\n",
    "print('seg3: ' + '|'.join(jieba.cut(test_str2, HMM=False)))\n",
    "jieba.suggest_freq(('台', '中'), True)\n",
    "print('seg4: ' + '|'.join(jieba.cut(test_str2, HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "自然语言处理 x\n"
     ]
    }
   ],
   "source": [
    "# 词性标注\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.load_userdict('user_dict.txt')\n",
    "words = pseg.cut(\"我爱自然语言处理\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed 563395.8451429922 bytes/second\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append(\"../../\")\n",
    "import jieba\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "jieba.enable_parallel()\n",
    "\n",
    "url = 'http://36kr.com/p/5068410.html'\n",
    "req = urllib.request.Request(url)\n",
    "req.add_header('User-Agent', 'Mozilla/5.0')\n",
    "content = urllib.request.urlopen(req).read()\n",
    "\n",
    "t1 = time.time()\n",
    "words = \"/ \".join(jieba.cut(content))\n",
    "\n",
    "t2 = time.time()\n",
    "tm_cost = t2-t1\n",
    "\n",
    "log_f = open(\"1.log\",\"wb\")\n",
    "log_f.write(words.encode('utf-8'))\n",
    "\n",
    "print('speed %s bytes/second' % (len(content)/tm_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "# Tokenize：返回词语在原文的起止位置\n",
    "\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
